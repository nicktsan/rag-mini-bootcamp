{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workshop_code.agents import NaiveQaRagAgent\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def display_md(content):\n",
    "  display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "You can combine the indexer, retriever, and generator into a convenient abstracted interface like in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The term \"Naive RAG\" refers to a research paradigm in the field of AI, specifically in the context of the Retrieve-Augment-Generate (RAG) framework. Naive RAG represents the earliest methodology within the RAG family and is characterized by a traditional process that involves indexing, retrieval, and generation of information.\n",
       "\n",
       "In the Naive RAG approach, the process starts with indexing, where raw data in various formats like PDF, HTML, Word, and Markdown is cleaned, extracted, and converted into a uniform plain text format. This indexed data is then segmented into smaller, digestible chunks, encoded into vector representations using an embedding model, and stored in a vector database. This step is crucial for enabling efficient similarity searches during the retrieval phase.\n",
       "\n",
       "During the retrieval phase, when a user query is received, the RAG system transforms the query into a vector representation using the same encoding model used during indexing. It then computes similarity scores between the query vector and the vector representations of chunks within the indexed corpus. The system retrieves the top K chunks that demonstrate the greatest similarity to the query, which are then used as expanded context in the prompt.\n",
       "\n",
       "Finally, in the generation phase, the posed query and selected documents are synthesized into a coherent prompt. A large language model"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_uri = \"https://arxiv.org/html/2312.10997v5\"\n",
    "qa_agent = NaiveQaRagAgent()\n",
    "\n",
    "qa_agent.index(doc_uri)\n",
    "\n",
    "question = \"What is naive RAG?\"\n",
    "completion = qa_agent.query(question)\n",
    "display_md(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: inspect the code\n",
    "Look at the code in `./cheat_code/agents.py`. If anything doesn't make sense, let one of us know."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
